import os
import pandas as pd
from jinja2 import Environment, FileSystemLoader
from playwright.sync_api import sync_playwright
import math
import shutil
from PIL import Image, ImageFilter, ImageDraw, ImageFont
import re
import warnings
import sys

# --- T·∫ÆT C·∫¢NH B√ÅO PANDAS ---
warnings.simplefilter(action='ignore', category=FutureWarning)

# --- C·∫§U H√åNH ---
EXCEL_DIR = "excel_files"
HTML_DIR = "output_html"
IMAGE_DIR = "output_images"
DATA_CHECK_DIR = "data_check"

TARGET_WIDTH, TARGET_HEIGHT = 2000, 1300
ROW_HEIGHT = 108
ROWS_PER_PAGE = 10
DATA_COLS_TO_KEEP = 15
INDEX_COL_WIDTH = 50
TOP_3_COL_WIDTH = 200
OTHER_COL_WIDTH = 105
AVG_CHAR_WIDTH = 8.5
CELL_PADDING_X = 10
LINE_HEIGHT_ESTIMATE = 18

# --- C·∫§U H√åNH GI·ªöI H·∫†N LEAK ---
MAX_LEAK_TOLERANCE = 5  # Cho ph√©p l·ªçt t·ªëi ƒëa 5 l·ªói/file

# --- C·∫§U H√åNH WATERMARK ---
WATERMARK_TEXT = "DATALD.COM"
WATERMARK_OPACITY = 90  # ƒê·ªô ƒë·∫≠m nh·∫°t (0-255)
GRID_COLS = 3 
GRID_ROWS = 3 

# --- DANH S√ÅCH T·ª™ KH√ìA C·∫¶N M√É H√ìA (Case-insensitive) ---
KEYWORDS_TO_MASK = [
    "trangvang", 
    "scribd", 
    "hsct", 
    "hosocongty", 
    "masothue", 
    "data5s", 
    "google.com/maps/",
    "thu·∫ø",
    "thue"
]

# --- H√ÄM M√É H√ìA (MASKING) ---
def mask_all_chars(match):
    """Callback: Thay th·∫ø to√†n b·ªô chu·ªói kh·ªõp b·∫±ng d·∫•u *"""
    return '*' * len(match.group())

def mask_number_group(match):
    """Callback: M√£ h√≥a 50% ƒë·ªô d√†i c·ªßa c·ª•m s·ªë"""
    digit_str = match.group()
    length = len(digit_str)
    num_to_mask = math.ceil(length / 2)
    return ("*" * num_to_mask) + digit_str[num_to_mask:]

def mask_email_group(match):
    """Callback: M√£ h√≥a user c·ªßa email"""
    email = match.group()
    if '@' in email:
        user_part, domain_part = email.split('@', 1)
        masked_user = '*' * len(user_part)
        return f"{masked_user}@{domain_part}"
    return email

def mask_cell_value(value):
    """
    H√†m m√£ h√≥a trung t√¢m.
    Th·ª© t·ª± ∆∞u ti√™n: URL -> T·ª´ kh√≥a -> Email -> S·ªë
    """
    text = str(value)
    if not text or text.strip().lower() == 'nan':
        return ""
    
    # --- 1. M√É H√ìA URL (HTTPS/WWW) ---
    url_pattern = r'\b(?:https?://|www\.)\S+\b'
    text = re.sub(url_pattern, mask_all_chars, text)

    # --- 2. M√É H√ìA T·ª™ KH√ìA ƒê·∫∂C BI·ªÜT ---
    for keyword in KEYWORDS_TO_MASK:
        pattern = re.compile(re.escape(keyword), re.IGNORECASE)
        text = pattern.sub(mask_all_chars, text)

    # --- 3. M√É H√ìA EMAIL ---
    email_pattern = r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b'
    text = re.sub(email_pattern, mask_email_group, text)

    # --- 4. M√É H√ìA S·ªê ---
    text = re.sub(r'\d+', mask_number_group, text)
    
    return text

# --- H√ÄM KI·ªÇM TRA B·∫¢O M·∫¨T ---
def check_html_leakage_count(html_path, file_name_check):
    leak_count = 0
    details = []
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Check Email
        email_pattern = r'\b[a-zA-Z0-9][a-zA-Z0-9._%+-]*@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b'
        leaked_emails = re.findall(email_pattern, content)
        if leaked_emails:
            leak_count += len(leaked_emails)
            details.extend(leaked_emails)

        # Check S·ªë
        number_pattern = r'(?<!\*)\b\d{7,}\b'
        leaked_numbers = re.findall(number_pattern, content)
        if leaked_numbers:
            for num in leaked_numbers:
                if num in file_name_check: continue
                leak_count += 1
                details.append(num)
            
        return leak_count, details
    except Exception as e:
        print(f"L·ªói check file {html_path}: {e}")
        return 1, ["L·ªói ƒë·ªçc file"]

# --- C√ÅC H√ÄM H·ªñ TR·ª¢ D·ªÆ LI·ªÜU ---
def get_column_widths(df_chunk):
    if df_chunk.empty: return []
    try:
        avg_lengths = df_chunk.astype(str).map(lambda x: len(str(x).strip())).mean()
    except AttributeError:
        avg_lengths = df_chunk.astype(str).applymap(lambda x: len(str(x).strip())).mean()
    top_3_indices = avg_lengths.sort_values(ascending=False).head(3).index
    data_widths = []
    for i in range(len(df_chunk.columns)):
        if i in top_3_indices: data_widths.append(TOP_3_COL_WIDTH)
        else: data_widths.append(OTHER_COL_WIDTH)
    return [INDEX_COL_WIDTH] + data_widths

def get_cell_class(text, col_width):
    text_space = col_width - CELL_PADDING_X
    if text_space <= 0: return "no-wrap-text"
    num_lines = math.ceil(len(str(text).strip()) * AVG_CHAR_WIDTH / text_space)
    estimated_height = num_lines * LINE_HEIGHT_ESTIMATE
    return "wrap-text" if estimated_height <= ROW_HEIGHT else "no-wrap-text"

# --- CORE: T·∫†O HTML ---
def generate_html_for_sheet(df, file_name, sheet_name, template):
    generated_files = [] 
    
    if len(df.columns) > DATA_COLS_TO_KEEP: df = df.iloc[:, :DATA_COLS_TO_KEEP]
    df = df[df.apply(lambda row: any(str(cell).strip() != '' and str(cell).strip().lower() != 'nan' for cell in row), axis=1)]
    if df.empty: return []

    num_pages = math.ceil(len(df) / ROWS_PER_PAGE)
    for i in range(num_pages):
        page_df = df.iloc[i*ROWS_PER_PAGE : (i+1)*ROWS_PER_PAGE]
        temp_df = page_df.copy()
        while len(temp_df.columns) < DATA_COLS_TO_KEEP: temp_df[f'ph_{len(temp_df.columns)}'] = ''
        col_widths = get_column_widths(temp_df)

        page_data = []
        for r_idx, row in page_df.iterrows():
            row_cells = []
            for c_idx, cell in enumerate(row):
                val = mask_cell_value('' if str(cell).strip().lower() == 'nan' else cell)
                row_cells.append({"value": val, "class": get_cell_class(val, col_widths[c_idx+1])})
            while len(row_cells) < DATA_COLS_TO_KEEP: row_cells.append({"value": "", "class": "wrap-text"})
            page_data.append({"excel_row_num": r_idx + 1, "cells": row_cells})
        while len(page_data) < ROWS_PER_PAGE:
            page_data.append({"excel_row_num": " ", "cells": [{"value": "", "class": "wrap-text"}]*DATA_COLS_TO_KEEP})

        page_html_path = os.path.join(HTML_DIR, f"{file_name}_{sheet_name}_page_{i+1}.html")
        with open(page_html_path, 'w', encoding='utf-8') as f:
            f.write(template.render({"title": f"{file_name} - {sheet_name} - P{i+1}", "page_data": page_data, "column_widths": col_widths}))
        generated_files.append((f"PAGE_{i+1}", page_html_path, sheet_name))
        
    return generated_files

# --- H√ÄM X·ª¨ L√ù WATERMARK ---
def add_watermark_to_image(image_path):
    """
    Th√™m watermark 'datald.com' m·ªù v√†o ·∫£nh.
    """
    try:
        base_image = Image.open(image_path).convert("RGBA")
        width, height = base_image.size
        
        txt_layer = Image.new("RGBA", base_image.size, (255, 255, 255, 0))
        draw = ImageDraw.Draw(txt_layer)
        
        font_size = int(width / 25) 
        try:
            # Replit (Linux) th∆∞·ªùng d√πng font DejaVu
            font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
            if not os.path.exists(font_path):
                # Fallback n·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m font arial c·ª•c b·ªô ho·∫∑c m·∫∑c ƒë·ªãnh
                font_path = "arial.ttf"
            
            if os.path.exists(font_path):
                font = ImageFont.truetype(font_path, font_size)
            else:
                font = ImageFont.load_default()
        except IOError:
            font = ImageFont.load_default()
        
        step_x = width / GRID_COLS
        step_y = height / GRID_ROWS
        text_color = (150, 150, 150, WATERMARK_OPACITY)
        
        for r in range(GRID_ROWS):
            for c in range(GRID_COLS):
                center_x = (c * step_x) + (step_x / 2)
                center_y = (r * step_y) + (step_y / 2)
                
                bbox = draw.textbbox((0, 0), WATERMARK_TEXT, font=font)
                text_w = bbox[2] - bbox[0]
                text_h = bbox[3] - bbox[1]
                
                x = center_x - (text_w / 2)
                y = center_y - (text_h / 2)
                
                draw.text((x, y), WATERMARK_TEXT, font=font, fill=text_color)
        
        combined = Image.alpha_composite(base_image, txt_layer)
        combined = combined.convert("RGB")
        combined.save(image_path)
        
    except Exception as e:
        print(f"     ‚ö†Ô∏è L·ªói th√™m watermark: {e}")

# --- H√ÄM T·∫†O ·∫¢NH T·ª™ LIST HTML ---
def create_images_from_list(html_list, file_name):
    print(f"     ‚úÖ FILE H·ª¢P L·ªÜ. ƒêang t·∫°o {len(html_list)} ·∫£nh...")
    
    browser = None
    try:
        with sync_playwright() as p:
            # TR√äN REPLIT: 
            # 1. Kh√¥ng d√πng p.chromium.launch() m·∫∑c ƒë·ªãnh v√¨ n√≥ t√¨m b·∫£n download.
            # 2. Replit.nix ƒë√£ c√†i Chromium v√†o system path.
            # 3. Ta d√πng channel="chrome" ho·∫∑c "chromium" ƒë·ªÉ n√≥ t√¨m b·∫£n system.
            # 4. Quan tr·ªçng: Th√™m args ƒë·ªÉ ch·∫°y headless trong container.
            
            launch_args = [
                "--no-sandbox", 
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage", # Quan tr·ªçng cho Replit
                "--disable-gpu",
                "--font-render-hinting=none"
            ]

            # Th·ª≠ kh·ªüi ƒë·ªông tr√¨nh duy·ªát
            try:
                # C√°ch 1: Th·ª≠ d√πng b·∫£n Chromium c√†i qua Nix
                browser = p.chromium.launch(args=launch_args)
            except Exception:
                # C√°ch 2: N·∫øu l·ªói, th·ª≠ ch·ªâ ƒë·ªãnh executable_path (n·∫øu bi·∫øt)
                # Tr√™n Replit th∆∞·ªùng n√≥ n·∫±m ·ªü /nix/store/.../bin/chromium
                # Nh∆∞ng Playwright th∆∞·ªùng t·ª± t√¨m n·∫øu setup env ƒë√∫ng.
                print("     ‚ö†Ô∏è L·ªói launch m·∫∑c ƒë·ªãnh, ƒëang th·ª≠ c·∫•u h√¨nh fallback...")
                browser = p.chromium.launch(channel="chromium", args=launch_args)

            page = browser.new_page()
            page.set_viewport_size({"width": TARGET_WIDTH, "height": TARGET_HEIGHT})
            
            for type_label, html_path, sheet_name in html_list:
                sheet_output_dir = os.path.join(IMAGE_DIR, file_name, sheet_name)
                os.makedirs(sheet_output_dir, exist_ok=True)

                img_filename = os.path.basename(html_path).replace(".html", ".png")
                img_path = os.path.join(sheet_output_dir, img_filename)
                
                # 1. Ch·ª•p ·∫£nh m√†n h√¨nh
                page.goto(f"file://{os.path.abspath(html_path)}")
                page.screenshot(path=img_path, full_page=False)
                
                # 2. Th√™m Watermark
                add_watermark_to_image(img_path)
            
            browser.close()
            return True # Th√†nh c√¥ng

    except Exception as e:
        print(f"‚ùå L·ªói CRITICAL khi ch·∫°y Playwright: {e}")
        print("üí° G·ª¢I √ù: H√£y ki·ªÉm tra file 'replit.nix' ƒë√£ c√≥ 'pkgs.chromium' v√† 'pkgs.playwright-driver' ch∆∞a.")
        if browser:
            try: browser.close()
            except: pass
        return False

def cleanup_htmls(html_list):
    for _, path, _ in html_list:
        if os.path.exists(path):
            os.remove(path)

# --- WORKFLOW CH√çNH ---
def process_excel_file_workflow(excel_path, template):
    file_name = os.path.splitext(os.path.basename(excel_path))[0]
    print(f"\n--- FILE: {os.path.basename(excel_path)} ---")
    
    try:
        all_sheets = pd.read_excel(excel_path, sheet_name=None, header=None)
    except Exception as e:
        print(f"L·ªói ƒë·ªçc file: {e}")
        return

    def generate_all_htmls():
        total_htmls = []
        for sheet_name, df in all_sheets.items():
            sheet_htmls = generate_html_for_sheet(df, file_name, sheet_name, template)
            total_htmls.extend(sheet_htmls)
        return total_htmls

    # 1. T·∫°o HTML
    print(f"     1Ô∏è‚É£  Giai ƒëo·∫°n 1: T·∫°o HTML to√†n b·ªô c√°c sheet...")
    all_html_files = generate_all_htmls()
    if not all_html_files:
        print("     ‚ö†Ô∏è  File kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá.")
        return

    # 2. Check L·∫ßn 1
    print(f"     2Ô∏è‚É£  Giai ƒëo·∫°n 2: Qu√©t l·ªói b·∫£o m·∫≠t (Ng∆∞·ª°ng cho ph√©p: {MAX_LEAK_TOLERANCE} l·ªói)...")
    total_leaks = 0
    all_leak_details = []
    
    for _, html_path, _ in all_html_files:
        count, details = check_html_leakage_count(html_path, file_name)
        total_leaks += count
        all_leak_details.extend(details)
    
    should_retry = False
    if total_leaks > MAX_LEAK_TOLERANCE:
        print(f"     ‚ö†Ô∏è  C·∫£nh b√°o: Ph√°t hi·ªán {total_leaks} l·ªói. V√≠ d·ª•: {all_leak_details[:3]}...")
        print("     üîÑ ƒêang th·ª≠ t·∫°o l·∫°i (Retry to√†n b·ªô file)...")
        should_retry = True
    elif total_leaks > 0:
        print(f"     ‚ö†Ô∏è  Th√¥ng b√°o: Ph√°t hi·ªán {total_leaks} l·ªói (Trong ng∆∞·ª°ng cho ph√©p). Ti·∫øp t·ª•c.")
    else:
        print(f"     ‚úÖ Tuy·ªát v·ªùi: Kh√¥ng ph√°t hi·ªán l·ªói n√†o.")

    # 3. Retry n·∫øu c·∫ßn
    if should_retry:
        cleanup_htmls(all_html_files)
        all_html_files = generate_all_htmls()
        total_leaks = 0
        all_leak_details = []
        for _, html_path, _ in all_html_files:
            count, details = check_html_leakage_count(html_path, file_name)
            total_leaks += count
            all_leak_details.extend(details)
            
    # 4. Quy·∫øt ƒë·ªãnh cu·ªëi c√πng
    if total_leaks > MAX_LEAK_TOLERANCE:
        # TR∆Ø·ªúNG H·ª¢P: L·ªói qu√° nhi·ªÅu -> C·∫ÆT FILE SANG DATA_CHECK
        print(f"     ‚ùå STOP: V·∫´n c√≤n {total_leaks} l·ªói sau khi retry.")
        
        dest_path = os.path.join(DATA_CHECK_DIR, os.path.basename(excel_path))
        try:
            if not os.path.exists(dest_path):
                shutil.move(excel_path, dest_path)
                print(f"     -> üìÇ ƒê√£ C·∫ÆT (MOVE) file Excel sang '{DATA_CHECK_DIR}'")
            else:
                print(f"     -> ‚ö†Ô∏è File Excel ƒë√£ t·ªìn t·∫°i trong '{DATA_CHECK_DIR}'. X√≥a file g·ªëc.")
                os.remove(excel_path)
        except Exception as move_err:
             print(f"     -> ‚ùå L·ªói khi di chuy·ªÉn file: {move_err}")

        cleanup_htmls(all_html_files)
        print("     üö´ ƒê√£ h·ªßy b·ªè output cho to√†n b·ªô file n√†y.")
        return 
    
    else:
        # TR∆Ø·ªúNG H·ª¢P: Th√†nh c√¥ng ho·∫∑c l·ªói √≠t -> T·∫†O ·∫¢NH & GI·ªÆ NGUY√äN FILE G·ªêC
        success = create_images_from_list(all_html_files, file_name)
        cleanup_htmls(all_html_files)
        
        if success:
            print(f"     ‚úÖ ƒê√£ ho√†n th√†nh x·ª≠ l√Ω file: {os.path.basename(excel_path)} (File g·ªëc ƒë∆∞·ª£c gi·ªØ l·∫°i)")

# --- MAIN ---
def main():
    print(f"üöÄ B·∫Øt ƒë·∫ßu... (Replit Compatible + Full Masking + No Delete Success)")
    os.makedirs(HTML_DIR, exist_ok=True)
    os.makedirs(IMAGE_DIR, exist_ok=True)
    os.makedirs(DATA_CHECK_DIR, exist_ok=True)

    env = Environment(loader=FileSystemLoader('.'))
    template = env.get_template('template.html')

    excel_files = [f for f in os.listdir(EXCEL_DIR) if f.endswith(('.xlsx', '.xls'))]
    if not excel_files:
        print("Kh√¥ng t√¨m th·∫•y file Excel.")
        return

    for filename in excel_files:
        excel_path = os.path.join(EXCEL_DIR, filename)
        process_excel_file_workflow(excel_path, template)

    if os.path.exists(HTML_DIR):
        try: shutil.rmtree(HTML_DIR)
        except: pass
        
    print("\n‚úÖ HO√ÄN T·∫§T. Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c 'output_images' v√† 'data_check'.")

if __name__ == "__main__":
    main()